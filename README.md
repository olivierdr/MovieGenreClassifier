# Movie Genre Classifier

This project focuses on classifying movie synopses into one of three genres: cult, paranormal, or dramatic. It includes dataset exploration, cleaning, training and evaluation of two classification models, and a demo application built with Streamlit. A Dockerfile is also provided for easy containerized deployment.

## Dataset Exploration and Cleaning

As a first step, I explored the dataset and noticed that although the data was relatively well structured, several inconsistencies were present. Some rows featured the same movie title but with different synopses, others had identical synopses associated with different titles, and in some cases, the same title and synopsis were assigned different labels.

To address these issues, I designed the following data cleaning strategy:

- If a movie title appeared multiple times with different synopses, I computed their semantic similarity.  
  - If the synopses were not similar (similarity < 0.8), I flagged those entries as `ambiguous=True`.  
  - Otherwise, I kept the longest version.  

- If a synopsis was linked to multiple movie titles:  
  - If the labels matched, I kept the first instance (the title itself is not informative for classification).  
  - If the labels differed, the entry was flagged as `ambiguous=True`.

### Dataset Insights

- Original dataset size: 1,566 rows  
- Cleaned dataset size: 1,528 rows  
- Ambiguous entries flagged: 38 rows  
- No missing values found  
- 33 rows with duplicate titles  
- 40 rows with duplicate synopses  
- 22 pairs of similar synopses (similarity threshold: 0.8)  

**Label distribution:**  
- cult: 1,033 (65.96%)  
- paranormal: 366 (23.37%)  
- dramatic: 167 (10.66%)  

**Synopsis length statistics:**  
- Mean synopsis length: 5,219 characters  
- Strong concentration around 4,500 characters  
- Long tail of distribution reaching up to 50,000 characters  

## Modeling Approaches

Two distinct modeling strategies were employed to classify the synopses into the three genres.

### TF-IDF + Logistic Regression

The first approach uses a bag-of-words representation with TF-IDF vectorization followed by logistic regression to identify class-specific word usage patterns.

**Performance metrics:**  
- Macro-average F1-score: 58%  
- Weighted-average F1-score: 69%  

These metrics were chosen because the macro-average F1 treats all classes equally, which is important in the context of class imbalance, while the weighted-average F1 accounts for the support of each class.

### SentenceTransformer Embeddings + Classifier

The second approach uses embeddings generated by `SentenceTransformer('all-MiniLM-L6-v2')` to represent synopses as dense vectors. A classifier was then trained on these embeddings.

**Performance after 10 epochs:**  
- Macro-average F1-score: 32%  
- Weighted-average F1-score: 51%  

This suggests that word choice may be more discriminative than semantic similarity in this case. It also raises questions about the labeling quality: how were the tags assigned—manually or automatically? Improving label consistency and class definition could significantly enhance classification performance.

The embedding-based model mostly predicts the `cult` class and struggles to distinguish the others effectively.

## Additional Analyses

It would be valuable to investigate which words are most discriminative for each class in the TF-IDF model and to visualize the embeddings in 2D or 3D space to better understand class separability. This can provide further insights into model behavior.

## Streamlit Application

A demo application was developed using Streamlit due to its simplicity and tight integration with Python. The app allows users to upload a `.txt` file or paste a synopsis and receive predictions from both models for comparison.

## Bonus Question – Multi-Label Classification

In cases where a movie can have multiple genre tags, possible approaches include one-vs-rest binary classifiers for each label, classifier chains to capture label dependencies, or neural networks with sigmoid outputs for multi-label prediction.

Challenges in this setting include handling label imbalance, accounting for label correlations, choosing appropriate evaluation metrics (such as micro/macro F1 or Hamming loss), and tuning thresholds for each class.

---

## Project Structure

```
MovieGenreClassifier/
├── data/
│   ├── raw/           # Original, immutable data
│   └── processed/     # Cleaned and processed data
├── outputs/
│   ├── analysis/      # Data analysis results and plots
│   ├── logs/         # Log files for data processing and model training
│   └── models/       # Trained models and model artifacts
├── src/
│   ├── data/         # Data processing scripts
│   │   ├── analysis.py    # Data exploration and analysis
│   │   └── clean_dataset.py  # Data cleaning pipeline
│   ├── models/       # Model training and evaluation
│   │   ├── model.py      # Model definitions
│   │   └── train.py      # Training pipeline
│   ├── utils/        # Utility functions
│   └── app.py        # Streamlit web application
├── tests/            # Test files
├── requirements.txt  # Project dependencies
└── README.md        # Project documentation
```

## Setup

1. Create a virtual environment:
```bash
python -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

## Pipeline

The project follows this pipeline:

1. Data Analysis and Cleaning:
```bash
# Run data analysis
python src/data/analysis.py

# Run data cleaning
python src/data/clean_dataset.py
```
This will:
- Analyze the raw data and generate plots in `outputs/analysis/`
- Clean the data and save processed files in `data/processed/`
- Generate logs in `outputs/logs/`

2. Model Training:
```bash
python src/models/train.py
```
This will:
- Train both TF-IDF and Embedding models
- Save models in `outputs/models/`
- Generate training logs in `outputs/logs/`

3. Web Application:
```bash
streamlit run src/app.py
```
This will:
- Start a web interface for movie genre prediction
- Use both trained models for predictions

## Development

- Use `src/` directory for source code
- Add tests in `tests/` directory
- Log files are stored in `outputs/logs/`
- Models are saved in `outputs/models/`
- Analysis results and plots are in `outputs/analysis/`

## Data Files

- Raw data: `data/raw/task.csv`
- Processed data:
  - `data/processed/movies_cleaned.csv`: Clean dataset for training
  - `data/processed/movies_checked_ambiguous.csv`: Full dataset with ambiguity flags
  - `data/processed/movies_ambiguous.csv`: Only ambiguous entries

## License

[To be added: License information]